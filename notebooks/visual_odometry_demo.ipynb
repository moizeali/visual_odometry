{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Visual Odometry System Demo\n",
    "\n",
    "This notebook demonstrates the Enhanced Visual Odometry System capabilities.\n",
    "\n",
    "## Features Covered:\n",
    "- Data loading and preprocessing\n",
    "- Visual odometry algorithms\n",
    "- Real-time processing\n",
    "- Performance analysis\n",
    "- Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Add backend to path\n",
    "sys.path.append('../backend')\n",
    "\n",
    "# Import our modules\n",
    "from core.visual_odometry import (\n",
    "    VisualOdometryPipeline, \n",
    "    CameraParams, \n",
    "    MonocularVO,\n",
    "    FeatureDetector\n",
    ")\n",
    "from data.dataset_loader import DatasetManager\n",
    "from utils.metrics import MetricsCollector\n",
    "from utils.visualization import TrajectoryPlotter\n",
    "from utils.logger import setup_logger\n",
    "\n",
    "# Setup\n",
    "logger = setup_logger(\"vo_demo\")\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize System Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "dataset_manager = DatasetManager(data_dir=\"../datasets\")\n",
    "metrics_collector = MetricsCollector()\n",
    "plotter = TrajectoryPlotter()\n",
    "\n",
    "# Camera parameters (typical values)\n",
    "camera_params = CameraParams(\n",
    "    fx=525.0,\n",
    "    fy=525.0,\n",
    "    cx=319.5,\n",
    "    cy=239.5\n",
    ")\n",
    "\n",
    "print(\"‚úÖ System components initialized\")\n",
    "print(f\"üìä Camera intrinsics: fx={camera_params.fx}, fy={camera_params.fy}\")\n",
    "print(f\"üìç Principal point: cx={camera_params.cx}, cy={camera_params.cy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sample data\n",
    "print(\"üì• Preparing sample data...\")\n",
    "sample_path = dataset_manager.prepare_sample_data()\n",
    "print(f\"‚úÖ Sample data created at: {sample_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "dataset = dataset_manager.load_dataset('sample')\n",
    "print(f\"üìä Dataset info:\")\n",
    "print(f\"  - Type: {dataset['type']}\")\n",
    "print(f\"  - Sequence: {dataset['sequence']}\")\n",
    "print(f\"  - Number of frames: {dataset['num_frames']}\")\n",
    "print(f\"  - Images path: {len(dataset['images'])} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Detection Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different feature detectors\n",
    "detectors = ['ORB', 'SIFT']\n",
    "test_image_path = dataset['images'][0]\n",
    "test_image = cv2.imread(test_image_path)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(detectors), figsize=(15, 5))\n",
    "if len(detectors) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, detector_type in enumerate(detectors):\n",
    "    try:\n",
    "        # Create detector\n",
    "        detector = FeatureDetector(detector_type)\n",
    "        \n",
    "        # Detect features\n",
    "        keypoints, descriptors = detector.detect_and_compute(test_image)\n",
    "        \n",
    "        # Draw keypoints\n",
    "        img_with_keypoints = cv2.drawKeypoints(\n",
    "            test_image, keypoints, None, color=(0, 255, 0), flags=0\n",
    "        )\n",
    "        \n",
    "        # Convert BGR to RGB for matplotlib\n",
    "        img_rgb = cv2.cvtColor(img_with_keypoints, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[i].imshow(img_rgb)\n",
    "        axes[i].set_title(f'{detector_type}: {len(keypoints)} keypoints')\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        print(f\"‚úÖ {detector_type}: {len(keypoints)} keypoints detected\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {detector_type} failed: {e}\")\n",
    "        axes[i].text(0.5, 0.5, f'{detector_type}\\nFailed', \n",
    "                    ha='center', va='center', transform=axes[i].transAxes)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visual Odometry Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visual odometry pipeline\n",
    "vo_pipeline = VisualOdometryPipeline(\n",
    "    camera_params=camera_params,\n",
    "    mode='mono',\n",
    "    detector_type='ORB'\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting visual odometry processing...\")\n",
    "\n",
    "# Start metrics collection\n",
    "session_id = metrics_collector.start_session(\n",
    "    dataset='sample',\n",
    "    sequence='synthetic',\n",
    "    algorithm='ORB_monocular'\n",
    ")\n",
    "\n",
    "# Process images\n",
    "results = []\n",
    "processing_times = []\n",
    "\n",
    "for i, image_path in enumerate(dataset['images'][:20]):  # Process first 20 frames\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load and process image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        continue\n",
    "    \n",
    "    # Process frame\n",
    "    pose, stats = vo_pipeline.vo.process_frame(image)\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    processing_times.append(processing_time)\n",
    "    \n",
    "    # Record metrics\n",
    "    metrics_collector.record_frame(\n",
    "        frame_number=i,\n",
    "        processing_time=processing_time,\n",
    "        keypoints=stats.get('keypoints_count', 0),\n",
    "        matches=stats.get('matches_count', 0),\n",
    "        inliers=stats.get('inliers_count', 0),\n",
    "        position=pose.t.flatten().tolist(),\n",
    "        rotation=pose.R.tolist()\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'frame': i,\n",
    "        'pose': pose,\n",
    "        'stats': stats,\n",
    "        'processing_time': processing_time\n",
    "    })\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        print(f\"üìä Frame {i}: {stats.get('keypoints_count', 0)} keypoints, \"\n",
    "              f\"{stats.get('matches_count', 0)} matches, \"\n",
    "              f\"{processing_time:.3f}s\")\n",
    "\n",
    "# End metrics collection\n",
    "session = metrics_collector.end_session(success=True)\n",
    "print(f\"‚úÖ Processing completed: {len(results)} frames\")\n",
    "print(f\"‚ö° Average FPS: {1.0/np.mean(processing_times):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trajectory Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trajectory data\n",
    "trajectory = vo_pipeline.get_trajectory_array()\n",
    "\n",
    "if len(trajectory) > 0:\n",
    "    print(f\"üìà Trajectory contains {len(trajectory)} poses\")\n",
    "    print(f\"üéØ Start position: [{trajectory[0, 0]:.2f}, {trajectory[0, 1]:.2f}, {trajectory[0, 2]:.2f}]\")\n",
    "    print(f\"üèÅ End position: [{trajectory[-1, 0]:.2f}, {trajectory[-1, 1]:.2f}, {trajectory[-1, 2]:.2f}]\")\n",
    "    \n",
    "    # Calculate trajectory length\n",
    "    distances = np.linalg.norm(np.diff(trajectory, axis=0), axis=1)\n",
    "    total_distance = np.sum(distances)\n",
    "    print(f\"üìè Total distance traveled: {total_distance:.2f} meters\")\n",
    "    \n",
    "    # Plot 2D trajectory\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(trajectory[:, 0], trajectory[:, 2], 'b-', linewidth=2, label='Estimated trajectory')\n",
    "    plt.scatter(trajectory[0, 0], trajectory[0, 2], c='green', s=100, marker='o', label='Start')\n",
    "    plt.scatter(trajectory[-1, 0], trajectory[-1, 2], c='red', s=100, marker='s', label='End')\n",
    "    \n",
    "    plt.xlabel('X (meters)')\n",
    "    plt.ylabel('Z (meters)')\n",
    "    plt.title('Visual Odometry Trajectory (Top View)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 3D trajectory\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    ax.plot(trajectory[:, 0], trajectory[:, 1], trajectory[:, 2], 'b-', linewidth=2)\n",
    "    ax.scatter(trajectory[0, 0], trajectory[0, 1], trajectory[0, 2], \n",
    "              c='green', s=100, marker='o', label='Start')\n",
    "    ax.scatter(trajectory[-1, 0], trajectory[-1, 1], trajectory[-1, 2], \n",
    "              c='red', s=100, marker='s', label='End')\n",
    "    \n",
    "    ax.set_xlabel('X (meters)')\n",
    "    ax.set_ylabel('Y (meters)')\n",
    "    ax.set_zlabel('Z (meters)')\n",
    "    ax.set_title('3D Visual Odometry Trajectory')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No trajectory data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get session summary\n",
    "summary = metrics_collector.get_session_summary(session_id)\n",
    "\n",
    "print(\"üìä Performance Summary:\")\n",
    "print(f\"  Session ID: {summary['session_id']}\")\n",
    "print(f\"  Algorithm: {summary['algorithm']}\")\n",
    "print(f\"  Total frames: {summary['total_frames']}\")\n",
    "print(f\"  Duration: {summary['duration_seconds']:.2f} seconds\")\n",
    "print(f\"  Average FPS: {summary['fps']:.2f}\")\n",
    "print(f\"  Trajectory length: {summary['trajectory_length']:.2f} meters\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è Processing Time Statistics:\")\n",
    "proc_stats = summary['processing_time']\n",
    "print(f\"  Mean: {proc_stats['mean']*1000:.2f} ms\")\n",
    "print(f\"  Std: {proc_stats['std']*1000:.2f} ms\")\n",
    "print(f\"  Min: {proc_stats['min']*1000:.2f} ms\")\n",
    "print(f\"  Max: {proc_stats['max']*1000:.2f} ms\")\n",
    "\n",
    "print(\"\\nüéØ Feature Statistics:\")\n",
    "kp_stats = summary['keypoints']\n",
    "match_stats = summary['matches']\n",
    "print(f\"  Keypoints - Mean: {kp_stats['mean']:.1f}, Std: {kp_stats['std']:.1f}\")\n",
    "print(f\"  Matches - Mean: {match_stats['mean']:.1f}, Std: {match_stats['std']:.1f}\")\n",
    "print(f\"  Match ratio: {match_stats['mean']/kp_stats['mean']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics for plotting\n",
    "frame_numbers = [r['frame'] for r in results]\n",
    "keypoints_counts = [r['stats'].get('keypoints_count', 0) for r in results]\n",
    "matches_counts = [r['stats'].get('matches_count', 0) for r in results]\n",
    "processing_times_ms = [r['processing_time'] * 1000 for r in results]\n",
    "\n",
    "# Create metrics plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Visual Odometry Performance Metrics', fontsize=16)\n",
    "\n",
    "# Keypoints over time\n",
    "axes[0, 0].plot(frame_numbers, keypoints_counts, 'b-', linewidth=2)\n",
    "axes[0, 0].set_title('Keypoints Detected per Frame')\n",
    "axes[0, 0].set_xlabel('Frame Number')\n",
    "axes[0, 0].set_ylabel('Keypoints Count')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Matches over time\n",
    "axes[0, 1].plot(frame_numbers, matches_counts, 'g-', linewidth=2)\n",
    "axes[0, 1].set_title('Feature Matches per Frame')\n",
    "axes[0, 1].set_xlabel('Frame Number')\n",
    "axes[0, 1].set_ylabel('Matches Count')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Processing time\n",
    "axes[1, 0].plot(frame_numbers, processing_times_ms, 'r-', linewidth=2)\n",
    "axes[1, 0].set_title('Processing Time per Frame')\n",
    "axes[1, 0].set_xlabel('Frame Number')\n",
    "axes[1, 0].set_ylabel('Time (ms)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Match efficiency\n",
    "match_ratios = [m/k if k > 0 else 0 for k, m in zip(keypoints_counts, matches_counts)]\n",
    "axes[1, 1].plot(frame_numbers, match_ratios, 'purple', linewidth=2)\n",
    "axes[1, 1].set_title('Match Efficiency (Matches/Keypoints)')\n",
    "axes[1, 1].set_xlabel('Frame Number')\n",
    "axes[1, 1].set_ylabel('Ratio')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different algorithms\n",
    "algorithms = ['ORB']  # Add 'SIFT' if available\n",
    "comparison_results = {}\n",
    "\n",
    "for algo in algorithms:\n",
    "    try:\n",
    "        print(f\"üîÑ Testing {algo} algorithm...\")\n",
    "        \n",
    "        # Create new pipeline\n",
    "        test_pipeline = VisualOdometryPipeline(\n",
    "            camera_params=camera_params,\n",
    "            mode='mono',\n",
    "            detector_type=algo\n",
    "        )\n",
    "        \n",
    "        # Start new session\n",
    "        test_session_id = metrics_collector.start_session(\n",
    "            dataset='sample',\n",
    "            sequence='synthetic',\n",
    "            algorithm=f'{algo}_comparison'\n",
    "        )\n",
    "        \n",
    "        # Process subset of images\n",
    "        test_images = dataset['images'][:10]  # First 10 frames\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, image_path in enumerate(test_images):\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                frame_start = time.time()\n",
    "                pose, stats = test_pipeline.vo.process_frame(image)\n",
    "                frame_time = time.time() - frame_start\n",
    "                \n",
    "                metrics_collector.record_frame(\n",
    "                    frame_number=i,\n",
    "                    processing_time=frame_time,\n",
    "                    keypoints=stats.get('keypoints_count', 0),\n",
    "                    matches=stats.get('matches_count', 0),\n",
    "                    inliers=stats.get('inliers_count', 0),\n",
    "                    position=pose.t.flatten().tolist(),\n",
    "                    rotation=pose.R.tolist()\n",
    "                )\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        test_session = metrics_collector.end_session(success=True)\n",
    "        test_summary = metrics_collector.get_session_summary(test_session_id)\n",
    "        \n",
    "        comparison_results[algo] = {\n",
    "            'fps': test_summary['fps'],\n",
    "            'avg_keypoints': test_summary['keypoints']['mean'],\n",
    "            'avg_matches': test_summary['matches']['mean'],\n",
    "            'trajectory_length': test_summary['trajectory_length']\n",
    "        }\n",
    "        \n",
    "        print(f\"  ‚úÖ {algo}: {test_summary['fps']:.2f} FPS, \"\n",
    "              f\"{test_summary['keypoints']['mean']:.1f} keypoints avg\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå {algo} failed: {e}\")\n",
    "\n",
    "# Display comparison\n",
    "if comparison_results:\n",
    "    print(\"\\nüìä Algorithm Comparison:\")\n",
    "    for algo, results in comparison_results.items():\n",
    "        print(f\"\\n{algo}:\")\n",
    "        print(f\"  FPS: {results['fps']:.2f}\")\n",
    "        print(f\"  Avg Keypoints: {results['avg_keypoints']:.1f}\")\n",
    "        print(f\"  Avg Matches: {results['avg_matches']:.1f}\")\n",
    "        print(f\"  Trajectory Length: {results['trajectory_length']:.2f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export session data\n",
    "output_dir = Path('../output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export metrics\n",
    "export_file = output_dir / f\"metrics_{session_id}.json\"\n",
    "metrics_collector.export_session(session_id, str(export_file))\n",
    "print(f\"üìÅ Metrics exported to: {export_file}\")\n",
    "\n",
    "# Save trajectory\n",
    "if len(trajectory) > 0:\n",
    "    trajectory_file = output_dir / f\"trajectory_{session_id}.csv\"\n",
    "    np.savetxt(trajectory_file, trajectory, delimiter=',', \n",
    "               header='x,y,z', comments='', fmt='%.6f')\n",
    "    print(f\"üìç Trajectory saved to: {trajectory_file}\")\n",
    "\n",
    "print(\"\\n‚úÖ Demo completed successfully!\")\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"  - Try different feature detectors (SIFT, SURF)\")\n",
    "print(\"  - Test with real camera data\")\n",
    "print(\"  - Experiment with stereo visual odometry\")\n",
    "print(\"  - Compare with ground truth trajectories\")\n",
    "print(\"  - Run the web interface for real-time visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}